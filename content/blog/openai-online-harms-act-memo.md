---
title: "AI Chatbots Belong in the Online Harms Act"
date: 2026-02-24
excerpt: "After OpenAI flagged the Tumbler Ridge shooter's conversations but didn't alert Canadian law enforcement, Helen Hayes and I sent a memo to Ministers Solomon and Miller arguing that AI chatbots must be scoped into the forthcoming Online Harms Act."
---

Tonight, Ministers Solomon and Miller will sit down with OpenAI's senior safety team in Ottawa to discuss the company's protocols for flagging and escalating dangerous content. This meeting was prompted by the revelation that OpenAI flagged the Tumbler Ridge shooter's ChatGPT conversations multiple times last June, but chose not to contact Canadian law enforcement.

This morning my colleague Helen Hayes and I sent a [memo to both ministers](https://www.taylorowen.com/s/How-the-next-government-can-protect-Canadas-information-ecosystem.pdf) arguing that this incident, following the Grok deepfake crisis in January, demonstrates why consumer-facing AI chatbots need to be scoped into the forthcoming Online Harms Act.

The core of our argument: if Canada had a digital safety regulator with chatbots in scope, the government would already know how these companies flag dangerous content, what their escalation thresholds are, and whether their systems are adequate. Minister Solomon should not have needed to summon OpenAI to Ottawa to learn this. They would have been required to tell us.

Canada is the only G7 country with no digital safety regulator and no online safety legislation of any kind. That has to change, and it should change this parliamentary session.

Coverage of our memo and tonight's meeting in [The Globe and Mail](https://www.theglobeandmail.com/).
