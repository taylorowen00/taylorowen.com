---
title: "Our AI Strategy Task Force Submission on Trust and Safety"
date: 2026-02-02
excerpt: "Today we are publicly releasing my submission to the National AI Strategy Task Force on the theme of trust and safety. It argues that closing Canada's AI governance gap requires action on three fronts."
---

Today we are publicly releasing my submission to the National AI Strategy Task Force on the theme of trust and safety.

The submission argues that Canada faces a fundamental governance gap when it comes to AI. Only 34% of Canadians are willing to trust AI systems. Nearly 80% are concerned about negative outcomes. And 88% want stronger governance. This is not a literacy gap — it is a governance gap. And without closing it, neither the adoption the government seeks nor public confidence in AI will materialize.

Closing this gap requires action on three fronts:

1. **Citizen safety.** AI systems are being deployed at unprecedented pace, often without meaningful risk assessment. We need independent regulatory authority with the power to mandate risk assessments before deployment and ensure heightened protections for children.

2. **Information integrity.** AI now both curates and creates our information environment. We need mandatory AI labeling and provenance disclosure, and data access frameworks that allow researchers to study these systems.

3. **Democratic legitimacy.** Citizens must have meaningful agency over AI systems that affect their lives — recourse mechanisms, data portability, and structured public consultation.

The good news is that Canada does not need sweeping new legislation to act. Most of these measures can be implemented through two existing frameworks: an amended Online Harms Act and an amended Consumer Privacy Protection Act. Both had cross-partisan support. Both could be revived quickly.

You can read the full submission on the Centre for Media, Technology, and Democracy website.
